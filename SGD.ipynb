{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer, QuantileTransformer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import log_loss \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from mlens.ensemble import SuperLearner\n",
    "from mlens.preprocessing import Subset\n",
    "from mlens.model_selection import Evaluator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "from sklearn.utils import shuffle\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "1. Extracting features and targets from the data\n",
    "2. Converting 'era' column to integer to input it to the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = 'training_data.csv'\n",
    "tournament_data = 'tournament_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(training_data)\n",
    "tournament = pd.read_csv(tournament_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in list(train) if \"feature\" in f]\n",
    "targets = ['target_bernie']\n",
    "features.insert(0, 'era')\n",
    "\n",
    "X = train[features]\n",
    "Y = train[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['era'] = X['era'].apply(lambda x: re.sub('[era]', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle & Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_x Shape ::  (336830, 51)\n",
      "Train_y Shape ::  (336830, 1)\n",
      "Test_x Shape ::  (165902, 51)\n",
      "Test_y Shape ::  (165902, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y = shuffle(X, Y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "print \"Train_x Shape :: \", X_train.shape\n",
    "print \"Train_y Shape :: \", y_train.shape\n",
    "print \"Test_x Shape :: \", X_test.shape\n",
    "print \"Test_y Shape :: \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://blomadam.github.io/\n",
    "\n",
    "class ModelTransformer(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self, model=None):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        self.model.fit(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return self.model.transform(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "1. Parameter Optimization\n",
    "2. SGD for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('best cv score', -0.6924584390021604)\n",
      "('best paramas', {'fit__alpha': 0.001, 'scale__model': MinMaxScaler(copy=True, feature_range=(0, 1)), 'fit__penalty': 'elasticnet', 'fit__l1_ratio': 0.15})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline_sgd = Pipeline([\n",
    "        ('scale', ModelTransformer()),\n",
    "        ('fit', SGDClassifier(loss='log', random_state=1)),\n",
    "])\n",
    "\n",
    "params_sgd = {\n",
    "    'scale__model': [MinMaxScaler()],\n",
    "    'fit__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'fit__alpha':[0.0001, .001, .01],\n",
    "    'fit__l1_ratio':[.05,.15,.25],\n",
    "}\n",
    "    \n",
    "SGD = GridSearchCV(pipeline_sgd, param_grid=params_sgd, cv=3, scoring='neg_log_loss', verbose=1, n_jobs=-1)\n",
    "SGD.fit(X_train,y_train)\n",
    "print('best cv score', SGD.best_score_)\n",
    "print('best paramas', SGD.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.516444497224119\n",
      "Test Accuracy  : 0.513375366180034\n"
     ]
    }
   ],
   "source": [
    "predictions = SGD.predict(X_test)\n",
    "print \"Train Accuracy :\", accuracy_score(y_train, SGD.predict(X_train))\n",
    "print \"Test Accuracy  :\", accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament['era'] = tournament['era'].apply(lambda x: re.sub('[era]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament = tournament[tournament.data_type == 'validation']\n",
    "x_prediction = tournament[features]\n",
    "y_prediction = SGD.predict_proba(x_prediction)\n",
    "results = y_prediction[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined:                  id  probability\n",
      "0  n00183d2eed2c463     0.498673\n",
      "1  n00187fa497c9d5b     0.504528\n",
      "2  n001acd04f3617b7     0.469130\n",
      "3  n0043a13252683ee     0.504412\n",
      "4  n00535e274720abd     0.496509\n"
     ]
    }
   ],
   "source": [
    "ids = tournament['id']\n",
    "\n",
    "# Create your submission\n",
    "results_df = pd.DataFrame(data={'probability': results})\n",
    "joined = pd.DataFrame(ids).join(results_df)\n",
    "print \"joined:\", joined.head()\n",
    "\n",
    "# Save the predictions out to a CSV file.\n",
    "joined.to_csv(\"bernie_submission3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"bernie_submission3.csv\")\n",
    "\n",
    "# v = test[ test.data_type == 'validation' ].copy()\n",
    "validate_set = tournament.copy()\n",
    "\n",
    "validate_set = validate_set.merge( submission, on = 'id', how = 'left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'era', u'data_type', u'feature1', u'feature2', u'feature3',\n",
       "       u'feature4', u'feature5', u'feature6', u'feature7', u'feature8',\n",
       "       u'feature9', u'feature10', u'feature11', u'feature12', u'feature13',\n",
       "       u'feature14', u'feature15', u'feature16', u'feature17', u'feature18',\n",
       "       u'feature19', u'feature20', u'feature21', u'feature22', u'feature23',\n",
       "       u'feature24', u'feature25', u'feature26', u'feature27', u'feature28',\n",
       "       u'feature29', u'feature30', u'feature31', u'feature32', u'feature33',\n",
       "       u'feature34', u'feature35', u'feature36', u'feature37', u'feature38',\n",
       "       u'feature39', u'feature40', u'feature41', u'feature42', u'feature43',\n",
       "       u'feature44', u'feature45', u'feature46', u'feature47', u'feature48',\n",
       "       u'feature49', u'feature50', u'target_bernie', u'target_elizabeth',\n",
       "       u'target_jordan', u'target_ken', u'target_charles', u'target_frank',\n",
       "       u'target_hillary', u'probability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.data_type.value_counts()\n",
    "validate_set.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logloss & Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0.692720388656414\n",
      "121 4540 69.27% True\n",
      "0.691205693145769\n",
      "122 4626 69.12% True\n",
      "0.6920470223984226\n",
      "123 4582 69.20% True\n",
      "0.6926536605515791\n",
      "124 4604 69.27% True\n",
      "0.6926924792479007\n",
      "125 4673 69.27% True\n",
      "0.6922338368682034\n",
      "126 4663 69.22% True\n",
      "0.6942990417297664\n",
      "127 4675 69.43% False\n",
      "0.6923515812126897\n",
      "128 4632 69.24% True\n",
      "0.6906388746936871\n",
      "129 4713 69.06% True\n",
      "0.6925646454970055\n",
      "130 4752 69.26% True\n",
      "0.6925314536910303\n",
      "131 4817 69.25% True\n",
      "0.6938763903022958\n",
      "132 4807 69.39% False\n",
      "\n",
      "consistency: 83.3% (10/12)\n",
      "log loss:    69.25%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from math import log\n",
    "\n",
    "eras = validate_set.era.unique()\n",
    "print len(eras)\n",
    "\n",
    "good_eras = 0\n",
    "\n",
    "for era in eras:\n",
    "    tmp = validate_set[ validate_set.era == era ]\n",
    "    logloss = metrics.log_loss( tmp.target_bernie, tmp.probability )\n",
    "    print logloss\n",
    "    is_good = logloss < -log( 0.5 )\n",
    "\n",
    "    if is_good:\n",
    "        good_eras += 1\n",
    "\n",
    "    print( \"{} {} {:.2%} {}\".format( era, len( tmp ), logloss, is_good ))\n",
    "\n",
    "consistency = good_eras / float( len( eras ))\n",
    "print( \"\\nconsistency: {:.1%} ({}/{})\".format( consistency, good_eras, len( eras )))\n",
    "\n",
    "logloss = metrics.log_loss( validate_set.target_bernie, validate_set.probability )\n",
    "print( \"log loss:    {:.2%}\\n\".format( logloss ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
